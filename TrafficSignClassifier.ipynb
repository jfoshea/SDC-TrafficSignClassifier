{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SDC Traffic Sign Classifier** \n",
    "## Overview \n",
    "Develop a Deep Leaning Network to classify traffic signs. To accomplish this a Convolutional Neural Network (CNN) will be developed to classify traffic signs. Specifically the CNN will focus on German traffic signs. [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    " \n",
    "## Requirements\n",
    "\n",
    "The requirements are:\n",
    "\n",
    "- Architecure based on LeNet-5 implementation. \n",
    "- Outline any preprocessing techniques used (normalization, rgb to grayscale, etc)\n",
    "- Outline any balancing techniques used on the number of examples per label (some have more than others).\n",
    "- Evaluate if the Neural Network is over or underfitting?)\n",
    "- Generate fake data \n",
    "- The Neural Network needs to have a validation set accuracy >= 0.93 \n",
    "\n",
    "## Steps\n",
    "\n",
    "The steps involved are:\n",
    "- Get the Test Data and Display Attributes\n",
    "- Plot the Test Data\n",
    "- Plot Histogram of Test Data\n",
    "- Pre-process the data set\n",
    "- TrafficSignNet Architecture\n",
    "- Train, Validate and Test the Model\n",
    "- Features and Labels\n",
    "- Training Pipeline\n",
    "- Model Evaluation\n",
    "- Train the Model\n",
    "- Evaluate the Model\n",
    "- Test on random images\n",
    "- Predict the Sign Type for Each Image\n",
    "- Output Top 5 Softmax Probabilities for each image found on the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDC Helper Functions\n",
    "Below are the helper functions for Traffic Sign Classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Class for some useful Enums\n",
    "class Enum( tuple ): __getattr__ = tuple.index \n",
    "\n",
    "# Define Enum for handling Data Sets\n",
    "DataSet = Enum( ['TRAIN', 'VALID', 'TEST', 'RANDOM'] ) \n",
    "\n",
    "# Define Enum for different equalization modes\n",
    "EqualizeMode = Enum( ['NORMAL', 'ADAPTIVE'] ) \n",
    "\n",
    "def get_test_data( test_data_dir ):\n",
    "   \"\"\"Get Test Data\"\"\"\n",
    "   for filename in os.listdir( test_data_dir ):\n",
    "       if any( filename.endswith( f ) for f in ( '.p' ) ):\n",
    "           if filename == 'train.p':\n",
    "               with open(test_data_dir+'/'+filename, mode='rb') as f:\n",
    "                   train = pickle.load(f)\n",
    "           elif filename == 'valid.p':\n",
    "               with open(test_data_dir+'/'+filename, mode='rb') as f:\n",
    "                   valid = pickle.load(f)\n",
    "           elif filename == 'test.p':\n",
    "               with open(test_data_dir+'/'+filename, mode='rb') as f:\n",
    "                   test = pickle.load(f)\n",
    "           else:\n",
    "               print(\" unknown filename {}\".format( filename ) )\n",
    "   return train, valid,test\n",
    "\n",
    "def get_sign_names( test_data_dir ):\n",
    "   \"\"\"Extract sign names from CSV file\"\"\"\n",
    "   with open('signnames.csv', mode='r') as f:\n",
    "       reader = csv.reader(f) \n",
    "       next( reader ) \n",
    "       signs = list( reader ) \n",
    "   return signs \n",
    "\n",
    "def plot_dataset_images( dataset ): \n",
    "   \"\"\"Plot images in a neat fashion using subplot\"\"\"\n",
    "   plot_cols = 4\n",
    "   plot_rows = math.ceil( n_classes / plot_cols )\n",
    "   plt.figure( figsize = ( 15, 40 ), facecolor='white' )\n",
    "   for i in range( n_classes ):\n",
    "       plot_num = i+1\n",
    "       ax = plt.subplot( plot_rows, plot_cols, plot_num ) \n",
    "       if dataset == DataSet.TRAIN: \n",
    "           img = X_train[y_train == i] \n",
    "       elif dataset == DataSet.VALID: \n",
    "           img = X_valid[y_valid == i] \n",
    "       elif dataset == DataSet.TEST: \n",
    "           img = X_test[y_test == i] \n",
    "       else:\n",
    "           print(\" unknown dataset\") \n",
    "       plt.imshow( img[0, :, :, :] )\n",
    "       ax.set_title( signs[i][1], fontsize = 12 )\n",
    "   plt.tight_layout()\n",
    "\n",
    "def plot_histogram( data, dataset ): \n",
    "   \"\"\"Plot histogram to show distribution of test_data\"\"\"\n",
    "   plt.figure( figsize = ( 20, 10 ), facecolor='white' )\n",
    "   if dataset == DataSet.TRAIN: \n",
    "       plt.title( 'Histogram of X_train across all Class Ids', fontsize = 24 )\n",
    "   elif dataset == DataSet.VALID: \n",
    "       plt.title( 'Histogram of X_valid across all Class Ids', fontsize = 24 )\n",
    "   elif dataset == DataSet.TEST: \n",
    "       plt.title( 'Histogram of X_test across all Class Ids', fontsize = 24 )\n",
    "   else:\n",
    "       print(\" unknown plottype\") \n",
    "   plt.ylabel( 'Num Images per Class Id', fontsize = 16 )\n",
    "   plt.xlabel( 'Class Id', fontsize = 16 )\n",
    "   plt.hist( data, len( signs ) ) \n",
    "\n",
    "def equalize_data( img, mode ): \n",
    "   \"\"\"Applies Histogram Equalization to enhance contrast\"\"\"\n",
    "   img = img.copy() \n",
    "   if mode == EqualizeMode.ADAPTIVE: \n",
    "       lab = cv2.cvtColor( img, cv2.COLOR_BGR2LAB ) \n",
    "       lab_planes = cv2.split( lab ) \n",
    "       clahe = cv2.createCLAHE( clipLimit=2.0,tileGridSize=(8,8) ) \n",
    "       lab_planes[0] = clahe.apply(lab_planes[0]) \n",
    "       lab = cv2.merge(lab_planes) \n",
    "       img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR) \n",
    "   elif mode == EqualizeMode.NORMAL: \n",
    "       for channel in range( 3 ): \n",
    "           img[:,:,channel] = cv2.equalizeHist( img[:,:,channel] ) \n",
    "   else:\n",
    "       print(\" unknown mode\") \n",
    "   return img \n",
    "\n",
    "def normalize_data( img ): \n",
    "   \"\"\"Normalize to have zero mean\"\"\"\n",
    "   return ( img - 128. ) / 128. \n",
    "\n",
    "def find_images( img_dir ):\n",
    "   \"\"\"Find and return a list of various image file formats\"\"\"\n",
    "   image_files = []\n",
    "   for filename in os.listdir( img_dir ):\n",
    "       if any( filename.endswith( f ) for f in ( '.jpg', '.jpeg','.gif', '.png' ) ):\n",
    "           image_files.append( os.path.abspath( img_dir+'/'+filename ) )\n",
    "   return sorted( image_files ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Test Data and Show Attributes\n",
    "\n",
    "The test_data is a set of pickle files in dictionary format with 4 key/value pairs:\n",
    "- `features` A 4D array of raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `labels` A 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `sizes` A list of tuples, (width, height) representing the original width and height the image.\n",
    "- `coords` A list of tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Test Data\n",
    "train, valid, test = get_test_data( 'test_data' )\n",
    "\n",
    "# Extract the features and labels from the test data\n",
    "X_train = train['features']\n",
    "y_train = train['labels']\n",
    "\n",
    "X_valid = valid['features']\n",
    "y_valid = valid['labels']\n",
    "\n",
    "X_test  = test['features'] \n",
    "y_test  = test['labels'] \n",
    "\n",
    "# Display Test Data Summary\n",
    "n_train = X_train.shape[0]\n",
    "n_valid = X_valid.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len( set( y_train ) )\n",
    "\n",
    "print( \"Number of training examples =\", n_train )\n",
    "print( \"Number of validation examples =\", n_valid )\n",
    "print( \"Number of testing examples =\", n_test )\n",
    "print( \"Image data shape =\", image_shape )\n",
    "print( \"Number of classes =\", n_classes )\n",
    "\n",
    "# Get Sign Names\n",
    "signs = get_sign_names( 'test_data' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Images\n",
    "\n",
    "Sample only - Plot the first image from each ClassId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_images( DataSet.TRAIN )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histogram of Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram( y_train, DataSet.TRAIN )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Validation Images\n",
    "\n",
    "Sample only - Plot the first image from each ClassId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_images( DataSet.VALID )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histogram of Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram( y_valid, DataSet.VALID )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Test Images\n",
    "\n",
    "Sample only - Plot the first image from each ClassId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_images( DataSet.TEST )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histogram of Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram( y_test, DataSet.TEST )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data sets\n",
    "\n",
    "For now we just normalized the data for zero mean and equal variance using `(pixel - 128)/ 128`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process data\n",
    "#print(\"Equalize each data set\") \n",
    "\n",
    "equalize_mode = EqualizeMode.ADAPTIVE \n",
    "\n",
    "X_train = np.array( [ equalize_data( img, equalize_mode ) for img in X_train] )\n",
    "X_valid = np.array( [ equalize_data( img, equalize_mode ) for img in X_valid] )\n",
    "X_test  = np.array( [ equalize_data( img, equalize_mode ) for img in X_test] )\n",
    "\n",
    "print(\"Normalize each data set\") \n",
    "X_train = np.array( [ normalize_data( img ) for img in X_train] )\n",
    "X_valid = np.array( [ normalize_data( img ) for img in X_valid] )\n",
    "X_test  = np.array( [ normalize_data( img ) for img in X_test] )\n",
    "\n",
    "print(\"Calculate and print the Mean of each data set. Mean should be close to 0 \")\n",
    "print(\"X_train mean (normalized) = {}\".format( np.mean( X_train ) ) ) \n",
    "print(\"X_valid mean (normalized) = {}\".format( np.mean( X_valid ) ) ) \n",
    "print(\"X_test  mean (normalized) = {}\".format( np.mean( X_test ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Normalized and Equalized Training Images\n",
    "\n",
    "Sample only - Plot the first image from each ClassId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_images( DataSet.TRAIN )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrafficSignNet Architecture\n",
    "\n",
    "This architecture takes LeNet as the base design and adds a Dropout after each Regularization layer. Dropout was pioneered by Geoffrey Hinton and is known to work very well in reducing overfitting.\n",
    "I have run many training sesseions with Dropout and it definitely helps ( Consistenly get >=93% ).\n", 
    "- Layer 1: \n",
    "   - Input = 32x32x3. Output = 28x28x6.\n",
    "   - conv1_W: \n",
    "       - Uses a 5x5 filter  with input depth=3 and output depth=6.\n",
    "       - The output_height = (input_height - filter_height)+1/vertical_stride, i.e 32-5+1/1 = 28. \n",
    "       - The output_width = (input_width - filter_width)+1/horinzatal_stride, i.e.  32-5+1/1 = 28 \n",
    "   - conv1_b: \n",
    "       - Bias vector, length = output_depth \n",
    "   - conv1: \n",
    "       - Convolve the filter over the images and add bias\n",
    "       - Activate the output of conv1 with a RELU activation function\n",
    "       - Pool the output with a 2x2 kernel with a 2x2 stride which gives us a pooling output of 14x14x6\n",
    "       - Add a dropout layer with keep_prob < 1\n",
    "- Layer 2: \n",
    "   - Input = 14x14x6. Output = 5x5x16.\n",
    "   - The steps from Layer 1 are repeated to create another layer\n",
    "- Layer 3: \n",
    "   - Fully Connected Layer. \n",
    "   - Input = 400. Output = 120.\n",
    "- Layer 4: \n",
    "   - Fully Connected Layer. \n",
    "   - Input = 120. Output = 84.\n",
    "- Layer 5: \n",
    "   - Fully Connected Layer. \n",
    "   - Input = 84. Output = 43 which is number of classes in dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def TrafficSignNet( x ): \n",
    "   mu = 0 \n",
    "   sigma = 0.1 \n",
    "\n",
    "   # Layer 1: \n",
    "   conv1_W = tf.Variable( tf.truncated_normal( shape=(5, 5, 3, 6), mean = mu, stddev = sigma ) )\n",
    "   conv1_b = tf.Variable( tf.zeros(6) )\n",
    "   conv1   = tf.nn.conv2d( x, conv1_W, strides=[1, 1, 1, 1], padding='VALID' ) + conv1_b\n",
    "   conv1   = tf.nn.relu(conv1)\n",
    "   conv1   = tf.nn.max_pool( conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID' )\n",
    "   conv1   = tf.nn.dropout( conv1, keep_prob ) \n",
    "\n",
    "   # Layer 2: \n",
    "   conv2_W = tf.Variable( tf.truncated_normal( shape=(5, 5, 6, 16), mean = mu, stddev = sigma ) )\n",
    "   conv2_b = tf.Variable( tf.zeros( 16 ) )\n",
    "   conv2   = tf.nn.conv2d( conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID' ) + conv2_b\n",
    "   conv2   = tf.nn.relu( conv2 )\n",
    "   conv2   = tf.nn.max_pool( conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID' )\n",
    "   conv2   = tf.nn.dropout( conv2, keep_prob ) \n",
    "\n",
    "   # Flatten the output to create a single vector. Input = 5x5x16. Output = 400.\n",
    "   fc0   = flatten( conv2 )\n",
    "\n",
    "   # Layer 3: \n",
    "   fc1_W = tf.Variable( tf.truncated_normal( shape=(400, 120), mean = mu, stddev = sigma ) )\n",
    "   fc1_b = tf.Variable( tf.zeros( 120 ) )\n",
    "   fc1   = tf.matmul( fc0, fc1_W ) + fc1_b\n",
    "   fc1   = tf.nn.relu( fc1 )\n",
    "   fc1   = tf.nn.dropout( fc1, keep_prob ) \n",
    "\n",
    "   # Layer 4: \n",
    "   fc2_W  = tf.Variable( tf.truncated_normal( shape=(120, 84), mean = mu, stddev = sigma ) )\n",
    "   fc2_b  = tf.Variable( tf.zeros(84) )\n",
    "   fc2    = tf.matmul( fc1, fc2_W ) + fc2_b\n",
    "   fc2    = tf.nn.relu( fc2 )\n",
    "   fc2   = tf.nn.dropout( fc2, keep_prob ) \n",
    "\n",
    "   # Layer 5: \n",
    "   fc3_W  = tf.Variable( tf.truncated_normal( shape=(84, 43), mean = mu, stddev = sigma ) )\n",
    "   fc3_b  = tf.Variable( tf.zeros( 43 ) )\n",
    "   logits = tf.matmul( fc2, fc3_W ) + fc3_b\n",
    "   \n",
    "   return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validate and Test the Model\n",
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder( tf.float32,( None, 32, 32, 3 ) )\n",
    "y = tf.placeholder( tf.int32,( None ) )\n",
    "one_hot_y = tf.one_hot( y, n_classes )\n",
    "keep_prob = tf.placeholder( tf.float32 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "rate = 0.001\n",
    "\n",
    "logits = TrafficSignNet( x )\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits( labels=one_hot_y, logits=logits )\n",
    "loss_operation = tf.reduce_mean( cross_entropy )\n",
    "optimizer = tf.train.AdamOptimizer( learning_rate = rate )\n",
    "training_operation = optimizer.minimize( loss_operation )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal( tf.argmax( logits, 1 ), tf.argmax( one_hot_y, 1 ) )\n",
    "accuracy_operation = tf.reduce_mean( tf.cast(correct_prediction, tf.float32 ) )\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate( X_data, y_data ):\n",
    "    num_examples = len( X_data )\n",
    "    total_accuracy = 0\n",
    "    session = tf.get_default_session()\n",
    "    for offset in range( 0, num_examples, BATCH_SIZE ):\n",
    "        batch_x, batch_y = X_data[ offset:offset+BATCH_SIZE ], y_data[ offset:offset+BATCH_SIZE ]\n",
    "        accuracy = session.run( accuracy_operation, feed_dict={ x: batch_x, y: batch_y, keep_prob: 1.0 } )\n",
    "        total_accuracy += ( accuracy * len( batch_x ) )\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "Before each epoch, shuffle the training set.\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "Save the model after training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run( tf.global_variables_initializer() )\n",
    "    num_examples = len( X_train )\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range( EPOCHS ):\n",
    "        X_train, y_train = shuffle( X_train, y_train )\n",
    "        for offset in range( 0, num_examples, BATCH_SIZE ):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[ offset:end ], y_train[ offset:end ]\n",
    "            session.run( training_operation, feed_dict={ x: batch_x, y: batch_y, keep_prob: 0.80 } )\n",
    "            \n",
    "        validation_accuracy = evaluate( X_valid, y_valid )\n",
    "        print(\"EPOCH {} ...\".format( i+1 ) )\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy ) )\n",
    "        print()\n",
    "        \n",
    "    saver.save( session, './traffic_sign_net' )\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Do this once!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    training_set_accuracy = evaluate(X_train, y_train)\n",
    "    print( \"Training Set Accuracy = {:.3f}\".format( training_set_accuracy ) )\n",
    "\n",
    "    validation_set_accuracy = evaluate(X_valid, y_valid )\n",
    "    print( \"Validation Set Accuracy = {:.3f}\".format( validation_set_accuracy ) )\n",
    "\n",
    "    test_set_accuracy = evaluate(X_test, y_test)\n",
    "    print( \"Test Set Accuracy = {:.3f}\".format( test_set_accuracy ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print( \"Get Random Test Set\")\n",
    "random_images = find_images( 'random_traffic_signs' )\n",
    "\n",
    "print(\"Resize randome images to 32x32\") \n",
    "X_random = np.array( [ cv2.resize(plt.imread( img ), (32, 32) ) for img in random_images ] ) \n",
    "print( \"X_random.shape = \", X_random.shape )\n",
    "\n",
    "print(\"Equalize the data set\") \n",
    "X_random = np.array( [ equalize_data( img, equalize_mode ) for img in X_random] )\n",
    "\n",
    "print(\"Normalize each data set\") \n",
    "X_random = np.array( [ normalize_data( img ) for img in X_random] )\n",
    "\n",
    "print(\"Print the Mean of random data set. Mean should be close to 0 \")\n",
    "print(\"X_random mean = {}\".format( np.mean( X_random ) ) ) \n",
    "\n",
    "actual_label = [ 0,7,12,24,35,40 ] \n",
    "\n",
    "plt.figure( figsize = ( 15, 15 ), facecolor='white' )\n",
    "plot_cols = 2\n",
    "plot_rows = math.ceil( len(random_images) / plot_cols )\n",
    "for i in range( len(random_images) ): \n",
    "   plot_num = i+1\n",
    "   ax = plt.subplot( plot_rows, plot_cols, plot_num ) \n",
    "   plt.imshow(X_random[i, :, :, :])\n",
    "   ax.set_title( signs[actual_label[i]][1], fontsize = 12 )\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax( logits, 1 )\n",
    "\n",
    "with tf.Session() as session: \n",
    "   saver.restore( session, tf.train.latest_checkpoint('.') ) \n",
    "   predictions = session.run( prediction, feed_dict={ x: X_random, keep_prob: 1.0 } ) \n",
    "\n",
    "for i, p in enumerate( predictions ): \n",
    "   print(\"prediction label = {:2d}, actual label = {:2d}\".format(p, actual_label[i] ) ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
   "softmax_logits = tf.nn.softmax( logits ) \n",
   "top5 = tf.nn.top_k( softmax_logits, k=5 ) \n",
   "with tf.Session() as session: \n",
   "    saver.restore( session, tf.train.latest_checkpoint('.') ) \n",
   "    softmax_data = session.run( softmax_logits, feed_dict={ x: X_random, keep_prob: 1.0 } ) \n",
   "    top5_softmax = session.run( top5, feed_dict={ x: X_random, keep_prob: 1.0 } ) \n",
   "\n",
   "for i in range( len(random_images) ): \n",
   "    print( \"Image: {}, Softmax Probability 1: {:.4f}\".format( signs[ actual_label[i]][1], top5_softmax[0][i][0] ) )\n",
   "    print( \"Image: {}, Softmax Probability 2: {:.4f}\".format( signs[ actual_label[i]][1], top5_softmax[0][i][1] ) )\n",
   "    print( \"Image: {}, Softmax Probability 3: {:.4f}\".format( signs[ actual_label[i]][1], top5_softmax[0][i][2] ) )\n",
   "    print( \"Image: {}, Softmax Probability 4: {:.4f}\".format( signs[ actual_label[i]][1], top5_softmax[0][i][3] ) )\n",
   "    print( \"Image: {}, Softmax Probability 5: {:.4f}\".format( signs[ actual_label[i]][1], top5_softmax[0][i][4] ) )\n",
   "    print(\" \")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
